{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-25T18:16:18.541447Z","iopub.execute_input":"2023-01-25T18:16:18.542138Z","iopub.status.idle":"2023-01-25T18:16:18.545673Z","shell.execute_reply.started":"2023-01-25T18:16:18.542035Z","shell.execute_reply":"2023-01-25T18:16:18.544896Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import Flatten\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:16:18.547189Z","iopub.execute_input":"2023-01-25T18:16:18.547746Z","iopub.status.idle":"2023-01-25T18:16:23.136249Z","shell.execute_reply.started":"2023-01-25T18:16:18.547712Z","shell.execute_reply":"2023-01-25T18:16:23.135249Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'2.3.1'"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:16:23.137554Z","iopub.execute_input":"2023-01-25T18:16:23.137862Z","iopub.status.idle":"2023-01-25T18:16:23.142427Z","shell.execute_reply.started":"2023-01-25T18:16:23.137831Z","shell.execute_reply":"2023-01-25T18:16:23.141561Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_datagenerator = ImageDataGenerator(rescale = 1.0/225,\n                                        shear_range = 0.2,\n                                        zoom_range = 0.2,\n                                        horizontal_flip = True)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:16:23.145323Z","iopub.execute_input":"2023-01-25T18:16:23.145610Z","iopub.status.idle":"2023-01-25T18:16:23.154744Z","shell.execute_reply.started":"2023-01-25T18:16:23.145582Z","shell.execute_reply":"2023-01-25T18:16:23.153816Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"training_set = train_datagenerator.flow_from_directory('../input/dogs-cats-images/dataset/training_set',\n                                                      target_size = (64,64),\n                                                       batch_size = 32,\n                                                       class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:16:23.158427Z","iopub.execute_input":"2023-01-25T18:16:23.158809Z","iopub.status.idle":"2023-01-25T18:16:28.081061Z","shell.execute_reply.started":"2023-01-25T18:16:23.158776Z","shell.execute_reply":"2023-01-25T18:16:28.080103Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 8000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_datagenerator = ImageDataGenerator(rescale = 1.0/255)\ntest_set = test_datagenerator.flow_from_directory('../input/dogs-cats-images/dataset/test_set',\n                                                  target_size = (64,64),\n                                                  batch_size = 32,\n                                                  class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:16:28.084409Z","iopub.execute_input":"2023-01-25T18:16:28.084736Z","iopub.status.idle":"2023-01-25T18:16:28.399976Z","shell.execute_reply.started":"2023-01-25T18:16:28.084705Z","shell.execute_reply":"2023-01-25T18:16:28.398911Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Found 2000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Building Our CNN","metadata":{}},{"cell_type":"code","source":"cnn = tf.keras.models.Sequential()\n# Convolution \ncnn.add(tf.keras.layers.Conv2D(filters=32,padding = \"same\",kernel_size=3,activation='relu',input_shape=[64,64,3]))\n# pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n# Convolution\ncnn.add(tf.keras.layers.Conv2D(filters=64, padding = \"same\",kernel_size=3,activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n\n#flaterning\ncnn.add(tf.keras.layers.Flatten())\n# FC\ncnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\ncnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n# Output layer\ncnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:16:28.401384Z","iopub.execute_input":"2023-01-25T18:16:28.401721Z","iopub.status.idle":"2023-01-25T18:16:28.572563Z","shell.execute_reply.started":"2023-01-25T18:16:28.401689Z","shell.execute_reply":"2023-01-25T18:16:28.571416Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:16:28.574111Z","iopub.execute_input":"2023-01-25T18:16:28.574582Z","iopub.status.idle":"2023-01-25T18:16:28.584954Z","shell.execute_reply.started":"2023-01-25T18:16:28.574536Z","shell.execute_reply":"2023-01-25T18:16:28.583880Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 64, 64, 32)        896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 16384)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               2097280   \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 2,133,313\nTrainable params: 2,133,313\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training \ncnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\ncnn.fit(x=training_set,validation_data=test_set,epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:16:28.586239Z","iopub.execute_input":"2023-01-25T18:16:28.588408Z","iopub.status.idle":"2023-01-25T18:27:05.850670Z","shell.execute_reply.started":"2023-01-25T18:16:28.588355Z","shell.execute_reply":"2023-01-25T18:27:05.849862Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/10\n250/250 [==============================] - 86s 342ms/step - loss: 0.6517 - accuracy: 0.6111 - val_loss: 0.6211 - val_accuracy: 0.6530\nEpoch 2/10\n250/250 [==============================] - 61s 243ms/step - loss: 0.5769 - accuracy: 0.6919 - val_loss: 0.5872 - val_accuracy: 0.6955\nEpoch 3/10\n250/250 [==============================] - 61s 246ms/step - loss: 0.5465 - accuracy: 0.7207 - val_loss: 0.5202 - val_accuracy: 0.7435\nEpoch 4/10\n250/250 [==============================] - 62s 246ms/step - loss: 0.5123 - accuracy: 0.7455 - val_loss: 0.4987 - val_accuracy: 0.7540\nEpoch 5/10\n250/250 [==============================] - 61s 243ms/step - loss: 0.4820 - accuracy: 0.7635 - val_loss: 0.4978 - val_accuracy: 0.7590\nEpoch 6/10\n250/250 [==============================] - 61s 242ms/step - loss: 0.4723 - accuracy: 0.7710 - val_loss: 0.5301 - val_accuracy: 0.7215\nEpoch 7/10\n250/250 [==============================] - 60s 242ms/step - loss: 0.4506 - accuracy: 0.7861 - val_loss: 0.4788 - val_accuracy: 0.7635\nEpoch 8/10\n250/250 [==============================] - 61s 244ms/step - loss: 0.4359 - accuracy: 0.7996 - val_loss: 0.4592 - val_accuracy: 0.7920\nEpoch 9/10\n250/250 [==============================] - 60s 242ms/step - loss: 0.4161 - accuracy: 0.8031 - val_loss: 0.4631 - val_accuracy: 0.7785\nEpoch 10/10\n250/250 [==============================] - 60s 241ms/step - loss: 0.4108 - accuracy: 0.8099 - val_loss: 0.4695 - val_accuracy: 0.7825\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f720cb0ffd0>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\ntest_image = image.load_img('../input/dogs-cats-images/dataset/test_set/dogs/dog.4017.jpg',target_size=(64,64))\ntest_image = image.img_to_array(test_image)\ntest_image = test_image/255\ntest_image = np.expand_dims(test_image,axis=0)\nresult = cnn.predict(test_image)\nif result <= 0.5:\n    print(\"Input Image is cat\")\nelse:\n    print(\"Input Image is dog\")","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:27:05.854528Z","iopub.execute_input":"2023-01-25T18:27:05.856453Z","iopub.status.idle":"2023-01-25T18:27:06.003723Z","shell.execute_reply.started":"2023-01-25T18:27:05.856409Z","shell.execute_reply":"2023-01-25T18:27:06.002546Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Input Image is dog\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}